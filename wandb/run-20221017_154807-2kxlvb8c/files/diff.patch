diff --git a/__pycache__/dataset.cpython-35.pyc b/__pycache__/dataset.cpython-35.pyc
deleted file mode 100644
index ac426c3..0000000
Binary files a/__pycache__/dataset.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/dataset.cpython-37.pyc b/__pycache__/dataset.cpython-37.pyc
deleted file mode 100644
index 1a84020..0000000
Binary files a/__pycache__/dataset.cpython-37.pyc and /dev/null differ
diff --git a/__pycache__/dataset.cpython-38.pyc b/__pycache__/dataset.cpython-38.pyc
deleted file mode 100644
index 9458f23..0000000
Binary files a/__pycache__/dataset.cpython-38.pyc and /dev/null differ
diff --git a/__pycache__/losses.cpython-35.pyc b/__pycache__/losses.cpython-35.pyc
deleted file mode 100644
index 878135d..0000000
Binary files a/__pycache__/losses.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/losses.cpython-38.pyc b/__pycache__/losses.cpython-38.pyc
deleted file mode 100644
index b498a58..0000000
Binary files a/__pycache__/losses.cpython-38.pyc and /dev/null differ
diff --git a/__pycache__/model.cpython-35.pyc b/__pycache__/model.cpython-35.pyc
deleted file mode 100644
index ca12818..0000000
Binary files a/__pycache__/model.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/model.cpython-38.pyc b/__pycache__/model.cpython-38.pyc
deleted file mode 100644
index 170850f..0000000
Binary files a/__pycache__/model.cpython-38.pyc and /dev/null differ
diff --git a/__pycache__/networks.cpython-35.pyc b/__pycache__/networks.cpython-35.pyc
deleted file mode 100644
index 40a5991..0000000
Binary files a/__pycache__/networks.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/networks.cpython-38.pyc b/__pycache__/networks.cpython-38.pyc
deleted file mode 100644
index 7f81d24..0000000
Binary files a/__pycache__/networks.cpython-38.pyc and /dev/null differ
diff --git a/__pycache__/options.cpython-35.pyc b/__pycache__/options.cpython-35.pyc
deleted file mode 100644
index 6366af1..0000000
Binary files a/__pycache__/options.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/options.cpython-38.pyc b/__pycache__/options.cpython-38.pyc
deleted file mode 100644
index 6723163..0000000
Binary files a/__pycache__/options.cpython-38.pyc and /dev/null differ
diff --git a/__pycache__/resnet.cpython-35.pyc b/__pycache__/resnet.cpython-35.pyc
deleted file mode 100644
index 6bd0441..0000000
Binary files a/__pycache__/resnet.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/statistics.cpython-35.pyc b/__pycache__/statistics.cpython-35.pyc
deleted file mode 100644
index a995d91..0000000
Binary files a/__pycache__/statistics.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/statistics.cpython-38.pyc b/__pycache__/statistics.cpython-38.pyc
deleted file mode 100644
index 16c494f..0000000
Binary files a/__pycache__/statistics.cpython-38.pyc and /dev/null differ
diff --git a/__pycache__/test.cpython-35.pyc b/__pycache__/test.cpython-35.pyc
deleted file mode 100644
index a99b969..0000000
Binary files a/__pycache__/test.cpython-35.pyc and /dev/null differ
diff --git a/__pycache__/test.cpython-38.pyc b/__pycache__/test.cpython-38.pyc
deleted file mode 100644
index 6eda499..0000000
Binary files a/__pycache__/test.cpython-38.pyc and /dev/null differ
diff --git a/main.py b/main.py
index 9cce56c..fa23fd6 100644
--- a/main.py
+++ b/main.py
@@ -1,12 +1,14 @@
 from dataset import AlignedDataset
-from torch.utils.data import DataLoader
+from torch.utils.data import DataLoader, SubsetRandomSampler
 from torch import nn
 from model import FaceModel
 from options import opt
 import torchvision.utils as vutils
 import wandb
 import os
+import numpy as np
 import torch
+from tqdm import tqdm
 from statistics import PADMeter
 import logging
 from tensorboardX import SummaryWriter
@@ -28,6 +30,9 @@ writer = SummaryWriter(log_dir=run_dir)
 
 wandb.init(project="DFA_fork")
 
+def polarize(x, threshold=0.1):
+    return x.masked_fill_(x > threshold, 1)
+
 if __name__ == '__main__':
     best_res = 101
     train_batch_size = opt.batch_size
@@ -43,26 +48,29 @@ if __name__ == '__main__':
     ])
 
     transform_depth = T.Compose([
-        T.ToPILImage(),
-        T.Resize((256,256)),
+        T.ToPILImage(mode="L"),
+        T.Resize((256,256)), # another resize will be applied afterwards
+        # T.Resize((32,32)),
         T.ToTensor(),
+        # T.ConvertImageDtype(torch.float32),
         T.Lambda(lambda x: polarize(x)),
     ])
-    train_dataset = CASIAFASDDataset(os.path.join("/home/raul/image_datasets/casia-new/data/"),
+    train_dataset = CASIAFASDDataset(os.path.join("/home/rgpa18/image_datasets/casia-new/data/"),
                                      "train", transform=transform_src,
                                      depth_transform=transform_depth,
-                                     # nodepth_path=os.path.join(
-                                        # DATA, "casia-new/data/attack_depth.png")
+                                     nodepth_path=os.path.join(
+                                         "/home/rgpa18/image_datasets/casia-new/data/attack_depth.png")
                                      )
-    test_dataset = CASIAFASDDataset(os.path.join("/home/raul/image_datasets/casia-new/data/"),
+    test_dataset = CASIAFASDDataset(os.path.join("/home/rgpa18/image_datasets/casia-new/data/"),
                                      "test", transform=transform_src,
                                      depth_transform=transform_depth,
-                                     # nodepth_path=os.path.join(
-                                        # DATA, "casia-new/data/attack_depth.png")
+                                     nodepth_path=os.path.join(
+                                         "/home/rgpa18/image_datasets/casia-new/data/attack_depth.png")
                                      )
     dataset_sz = len(train_dataset)
     indices = list(range(dataset_sz))
     split = int(np.floor(.2 * dataset_sz))
+    shuffle = True
     if shuffle:
         np.random.seed(143)
         np.random.shuffle(indices)
@@ -73,9 +81,7 @@ if __name__ == '__main__':
                                    sampler=train_sampler, num_workers=8)
     dev_data_loader = DataLoader(train_dataset, batch_size=test_batch_size,
                                  sampler=val_sampler, num_workers=8) # using val as dev
-    test_data-loader = DataLoader(test_dataset, batch_size=test_batch_size, num_workers=8)
-
-    # TODO: report results on wandb
+    test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, num_workers=8)
 
     """
     test_data_loader = DataLoader(AlignedDataset(test_file_list,isTrain = False), batch_size=test_batch_size,
@@ -88,12 +94,12 @@ if __name__ == '__main__':
                                     shuffle = True,num_workers=8)
                                     """
 
-    wandb.watch(model)
+    # wandb.watch(model)
     writer.iter = 0
-    for e in range(opt.epoch):
+    for e in tqdm(range(opt.epoch), desc="Epochs", unit="epochs"):
         model.train()
         pad_meter_train = PADMeter()
-        for i, data in enumerate(train_data_loader):
+        for i, data in tqdm(enumerate(train_data_loader), desc="Batches", unit="batches"):
             model.set_input(data)
             model.optimize_parameters()
             class_output = nn.functional.softmax(model.output, dim=1)
@@ -110,11 +116,12 @@ if __name__ == '__main__':
                 img_save_dir = os.path.join(opt.checkpoints_dir, opt.name, "res")
                 if not os.path.exists(img_save_dir):
                     os.makedirs(img_save_dir)
-                logging.info(model.get_current_losses())
-                logging.info('HTER {pad_meter.hter:.4f} EER {pad_meter.eer:.4f} ACC {pad_meter.accuracy:.4f}'.format(
-                    pad_meter=pad_meter_train))
-                vutils.save_image(ret['fake_B'], "%s/epoch_%d_fake.png" % (img_save_dir, e), normalize=True)
-                vutils.save_image(ret['real_B'], "%s/epoch_%d_real.png" % (img_save_dir, e), normalize=True)
+                wandb.log(model.get_current_losses())
+                wandb.log({"HTER_train": pad_meter_train.hter, "EER_train": pad_meter_train.eer, "ACC_train": pad_meter_train.accuracy})
+                #print('HTER {pad_meter.hter:.4f} EER {pad_meter.eer:.4f} ACC {pad_meter.accuracy:.4f}'.format(
+                #     pad_meter=pad_meter_train))
+                # vutils.save_image(ret['fake_B'], "%s/epoch_%d_fake.png" % (img_save_dir, e), normalize=True)
+                # vutils.save_image(ret['real_B'], "%s/epoch_%d_real.png" % (img_save_dir, e), normalize=True)
 
 
         if e%1==0:
@@ -127,9 +134,9 @@ if __name__ == '__main__':
 
             pad_meter.get_hter_apcer_etal_at_thr(pad_dev_mater.threshold)
             pad_meter.get_accuracy(pad_dev_mater.threshold)
-            logging.info("epoch %d"%e)
-            logging.info('HTER {pad_meter.hter:.4f} EER {pad_meter.eer:.4f} ACC {pad_meter.accuracy:.4f}'.format(
-                pad_meter=pad_meter))
+            wandb.log({"HTER": pad_meter.hter, "EER": pad_meter.eer, "ACC": pad_meter.accuracy})
+            # print('HTER {pad_meter.hter:.4f} EER {pad_meter.eer:.4f} ACC {pad_meter.accuracy:.4f}'.format(
+            #     pad_meter=pad_meter))
             is_best = pad_meter.hter <= best_res
             best_res = min(pad_meter.hter, best_res)
             if is_best:
diff --git a/model.py b/model.py
index c9a50a5..53d7739 100644
--- a/model.py
+++ b/model.py
@@ -2,6 +2,7 @@ import networks
 import losses
 import torch
 from torch import nn
+from torchvision import transforms as T
 import os
 import itertools
 from collections import OrderedDict
@@ -49,11 +50,22 @@ class FaceModel(nn.Module):
                                                                     self.netClassifier.parameters()),lr=opt.lr, betas=(opt.beta1, 0.999),weight_decay=0.01)
 
     def set_input(self,input):
+        face = input[0]
+        depth = input[2]
+        res32 = T.Resize((32,32))
+        res256 = T.Resize((256,256))
+        self.real_A = res256(face).to(self.device)
+        self.real_A_32 = res32(face).to(self.device)
+        self.real_B = res32(depth).to(self.device)
+        self.label = input[4].long().to(self.device)
+        self.image_path = "/dev/null"
+        """
         self.real_A = input['A'].to(self.device)
         self.real_A_32 = input['A_32'].to(self.device)
         self.real_B = input['B'].to(self.device)
         self.label = torch.tensor(input['label']).to(self.device)
         self.image_path = input['A_paths']
+        """
 
     def forward(self):
         self.lantent_0,self.lantent_1 = self.netEncoder(self.real_A)
@@ -215,4 +227,4 @@ class FaceModel(nn.Module):
                (key == 'num_batches_tracked'):
                 state_dict.pop('.'.join(keys))
         else:
-            self.__patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)
\ No newline at end of file
+            self.__patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)
diff --git a/options.py b/options.py
index f04921e..1b62cbf 100644
--- a/options.py
+++ b/options.py
@@ -2,7 +2,7 @@ import argparse
 parser = argparse.ArgumentParser()
 
 parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')
-parser.add_argument('--batch_size', type=int, default=25, help='batch size')
+parser.add_argument('--batch_size', type=int, default=8, help='batch size')
 parser.add_argument('--epoch', type=int, default=30, help='epoch')
 parser.add_argument('--gpu_ids', type=str, default='0,1,2', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')
 
diff --git a/statistics.py b/statistics.py
index 8b3a11c..4e0d684 100644
--- a/statistics.py
+++ b/statistics.py
@@ -1,7 +1,7 @@
 import math
 import numpy as np
 from sklearn.metrics import roc_curve, accuracy_score
-from sklearn.metrics import roc_auc_score
+# from sklearn.metrics import roc_auc_score
 
 class PADMeter(object):
     """Presentation Attack Detection Meter"""
@@ -81,7 +81,7 @@ class PADMeter(object):
         self.bpcer = frr
         self.acer = (self.apcer + self.bpcer) /2.0
         self.hter = (far + frr) / 2.0
-        self.auc = roc_auc_score(self.label, self.output)
+        # self.auc = roc_auc_score(self.label, self.output)
 
 
     def get_accuracy(self,thr=None):
@@ -108,4 +108,4 @@ class AverageMeter(object):
         self.val = val
         self.sum += val * n
         self.count += n
-        self.avg = self.sum / self.count
\ No newline at end of file
+        self.avg = self.sum / self.count
